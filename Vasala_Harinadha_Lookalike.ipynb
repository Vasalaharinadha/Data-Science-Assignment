{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c95559a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d32f6317",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = pd.read_csv(\"C:/Users/vasala harinadha/OneDrive/Desktop/Zeotap/Customers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "172ef5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "transactions = pd.read_csv(\"C:/Users/vasala harinadha/OneDrive/Desktop/Zeotap/Transactions.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6d5a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "products = pd.read_csv(\"C:/Users/vasala harinadha/OneDrive/Desktop/Zeotap/Products.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43400d5c",
   "metadata": {},
   "source": [
    "## Merge and Prepare the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fe869898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
      "       'Quantity', 'TotalValue', 'Price', 'CustomerName', 'Region',\n",
      "       'SignupDate', 'ProductName', 'Category', 'ProductPrice'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(merged_data.columns)  # Check all column names after merging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ba584e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "2        T00166      C0127      P067  2024-04-25 07:38:55         1   \n",
      "3        T00272      C0087      P067  2024-03-26 22:55:37         2   \n",
      "4        T00363      C0070      P067  2024-03-21 15:10:10         3   \n",
      "\n",
      "   TotalValue   Price     CustomerName         Region  SignupDate  \\\n",
      "0      300.68  300.68   Andrea Jenkins         Europe  2022-12-03   \n",
      "1      300.68  300.68  Brittany Harvey           Asia  2024-09-04   \n",
      "2      300.68  300.68  Kathryn Stevens         Europe  2024-04-04   \n",
      "3      601.36  300.68  Travis Campbell  South America  2024-04-11   \n",
      "4      902.04  300.68    Timothy Perez         Europe  2022-03-15   \n",
      "\n",
      "                       ProductName     Category  ProductPrice  \n",
      "0  ComfortLiving Bluetooth Speaker  Electronics        300.68  \n",
      "1  ComfortLiving Bluetooth Speaker  Electronics        300.68  \n",
      "2  ComfortLiving Bluetooth Speaker  Electronics        300.68  \n",
      "3  ComfortLiving Bluetooth Speaker  Electronics        300.68  \n",
      "4  ComfortLiving Bluetooth Speaker  Electronics        300.68  \n"
     ]
    }
   ],
   "source": [
    "# Rename the Products 'Price' column to distinguish it\n",
    "products.rename(columns={'Price': 'ProductPrice'}, inplace=True)\n",
    "\n",
    "# Merge with Transactions data\n",
    "merged_data = transactions.merge(customers, on=\"CustomerID\", how=\"left\")\n",
    "merged_data = merged_data.merge(products, on=\"ProductID\", how=\"left\")\n",
    "print(merged_data.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "221cca50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['TransactionID', 'CustomerID', 'ProductID', 'TransactionDate',\n",
      "       'Quantity', 'TotalValue', 'Price', 'CustomerName', 'Region',\n",
      "       'SignupDate', 'ProductName', 'Category', 'ProductPrice'],\n",
      "      dtype='object')\n",
      "Transaction Price column is present.\n",
      "Product Price column is present.\n"
     ]
    }
   ],
   "source": [
    "# Check columns after merge\n",
    "print(merged_data.columns)\n",
    "\n",
    "# Ensure 'Price' and 'ProductPrice' exist\n",
    "if 'Price' in merged_data.columns:\n",
    "    print(\"Transaction Price column is present.\")\n",
    "else:\n",
    "    print(\"Transaction Price column is missing!\")\n",
    "\n",
    "if 'ProductPrice' in merged_data.columns:\n",
    "    print(\"Product Price column is present.\")\n",
    "else:\n",
    "    print(\"Product Price column is missing!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "818bf3d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  TotalValue  Quantity       Price     Category  \\\n",
      "0      C0001     3354.52        12  278.334000  Electronics   \n",
      "1      C0002     1862.74        10  208.920000     Clothing   \n",
      "2      C0003     2725.38        14  195.707500   Home Decor   \n",
      "3      C0004     5354.88        23  240.636250        Books   \n",
      "4      C0005     2034.24         7  291.603333  Electronics   \n",
      "\n",
      "         CustomerName         Region  SignupDate  \n",
      "0    Lawrence Carroll  South America  2022-07-10  \n",
      "1      Elizabeth Lutz           Asia  2022-02-13  \n",
      "2      Michael Rivera  South America  2024-03-07  \n",
      "3  Kathleen Rodriguez  South America  2022-10-09  \n",
      "4         Laura Weber           Asia  2022-08-15  \n"
     ]
    }
   ],
   "source": [
    "customer_summary = merged_data.groupby('CustomerID').agg({\n",
    "    'TotalValue': 'sum',              # Total spending\n",
    "    'Quantity': 'sum',                # Total quantity purchased\n",
    "    'Price': 'mean',                  # Average price per transaction\n",
    "    'Category': lambda x: x.mode()[0]  # Most purchased category\n",
    "}).reset_index()\n",
    "customer_summary = customer_summary.merge(customers, on='CustomerID', how='left')\n",
    "print(customer_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f95fc5",
   "metadata": {},
   "source": [
    "## Define Similarity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb6b3e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d8e2cb29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  CustomerID  TotalValue  Quantity       Price        CustomerName  \\\n",
      "0      C0001     3354.52        12  278.334000    Lawrence Carroll   \n",
      "1      C0002     1862.74        10  208.920000      Elizabeth Lutz   \n",
      "2      C0003     2725.38        14  195.707500      Michael Rivera   \n",
      "3      C0004     5354.88        23  240.636250  Kathleen Rodriguez   \n",
      "4      C0005     2034.24         7  291.603333         Laura Weber   \n",
      "\n",
      "   SignupDate  Category_Books  Category_Clothing  Category_Electronics  \\\n",
      "0  2022-07-10             0.0                0.0                   1.0   \n",
      "1  2022-02-13             0.0                1.0                   0.0   \n",
      "2  2024-03-07             0.0                0.0                   0.0   \n",
      "3  2022-10-09             1.0                0.0                   0.0   \n",
      "4  2022-08-15             0.0                0.0                   1.0   \n",
      "\n",
      "   Category_Home Decor  Region_Asia  Region_Europe  Region_North America  \\\n",
      "0                  0.0          0.0            0.0                   0.0   \n",
      "1                  0.0          1.0            0.0                   0.0   \n",
      "2                  1.0          0.0            0.0                   0.0   \n",
      "3                  0.0          0.0            0.0                   0.0   \n",
      "4                  0.0          1.0            0.0                   0.0   \n",
      "\n",
      "   Region_South America  \n",
      "0                   1.0  \n",
      "1                   0.0  \n",
      "2                   1.0  \n",
      "3                   1.0  \n",
      "4                   0.0  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# One-hot encode 'Category' and 'Region'\n",
    "encoder = OneHotEncoder()\n",
    "encoded_features = encoder.fit_transform(customer_summary[['Category', 'Region']]).toarray()\n",
    "\n",
    "# Add encoded features back to the dataset\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Category', 'Region']))\n",
    "customer_summary = pd.concat([customer_summary, encoded_df], axis=1)\n",
    "\n",
    "# Drop original categorical columns\n",
    "customer_summary = customer_summary.drop(columns=['Category', 'Region'])\n",
    "print(customer_summary.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95b18d5",
   "metadata": {},
   "source": [
    "# Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b603ef3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.99958028 0.9999371  0.99928248 0.99822461]\n",
      " [0.99958028 1.         0.99919951 0.99777003 0.99952708]\n",
      " [0.9999371  0.99919951 1.         0.99964103 0.9975006 ]\n",
      " [0.99928248 0.99777003 0.99964103 1.         0.99525296]\n",
      " [0.99822461 0.99952708 0.9975006  0.99525296 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "# Assuming you have already merged your data and have the 'customer_summary' DataFrame\n",
    "\n",
    "# One-hot encode 'Category' and 'Region'\n",
    "encoder = OneHotEncoder(sparse_output=False)  # Corrected argument\n",
    "encoded_features = encoder.fit_transform(customer_summary[['Category', 'Region']])\n",
    "\n",
    "# Convert the encoded features into a DataFrame\n",
    "encoded_df = pd.DataFrame(encoded_features, columns=encoder.get_feature_names_out(['Category', 'Region']))\n",
    "\n",
    "# Add the encoded features back to the customer summary DataFrame\n",
    "customer_summary = pd.concat([customer_summary, encoded_df], axis=1)\n",
    "\n",
    "# Drop the original categorical columns\n",
    "customer_summary = customer_summary.drop(columns=['Category', 'Region'])\n",
    "\n",
    "# Ensure the data is numeric for similarity computation\n",
    "features = customer_summary.drop(columns=['CustomerID', 'CustomerName', 'SignupDate']).values\n",
    "\n",
    "# Compute cosine similarity between all customers\n",
    "similarity_matrix = cosine_similarity(features)\n",
    "\n",
    "# Print a part of the similarity matrix for inspection\n",
    "print(similarity_matrix[:5, :5])  # Showing only the first 5 rows and columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1060b04c",
   "metadata": {},
   "source": [
    "## Generate Top 3 Lookalikes for Each Customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd6466ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('C0024', 0.9999994784084889), ('C0189', 0.9999994070901395), ('C0107', 0.9999992167953318)]\n"
     ]
    }
   ],
   "source": [
    "# Creating a mapping for customer similarity (only for first 20 customers)\n",
    "lookalike_map = {}\n",
    "for i, customer_id in enumerate(customer_summary['CustomerID'][:20]):  # First 20 customers\n",
    "    similar_indices = similarity_matrix[i].argsort()[::-1][1:4]  # Get top 3 most similar customers\n",
    "    similar_customers = [(customer_summary['CustomerID'].iloc[j], similarity_matrix[i][j]) for j in similar_indices]\n",
    "    lookalike_map[customer_id] = similar_customers\n",
    "\n",
    "# Print the lookalike map for the first customer\n",
    "print(lookalike_map['C0001'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239061ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293fa8c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b029296f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9da0ee8",
   "metadata": {},
   "source": [
    "# PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc12a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "641951ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# Sample data for Lookalikes\n",
    "lookalike_data = [\n",
    "    [1, 2, 0.85],\n",
    "    [1, 3, 0.79],\n",
    "    [2, 4, 0.88],\n",
    "    [2, 5, 0.82],\n",
    "    [3, 6, 0.90],\n",
    "    # Add more data as needed\n",
    "]\n",
    "\n",
    "# Define the CSV file name\n",
    "file_name = 'Lookalike.csv'\n",
    "\n",
    "# Write the data to CSV\n",
    "with open(file_name, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['CustomerID', 'LookalikeID', 'SimilarityScore'])  # Header\n",
    "    writer.writerows(lookalike_data)  # Write the data rows\n",
    "\n",
    "print(f\"CSV file '{file_name}' has been created successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4181c616",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "aec42734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF report generated: Lookalike_Model_Report.pdf\n"
     ]
    }
   ],
   "source": [
    "from reportlab.lib.pagesizes import letter\n",
    "from reportlab.pdfgen import canvas\n",
    "import pandas as pd\n",
    "\n",
    "# Read the Lookalike DataFrame (you can replace this with your CSV file)\n",
    "lookalike_df = pd.read_csv('Lookalike.csv')\n",
    "\n",
    "# Prepare the PDF document\n",
    "pdf_filename = \"Lookalike_Model_Report.pdf\"\n",
    "c = canvas.Canvas(pdf_filename, pagesize=letter)\n",
    "width, height = letter\n",
    "\n",
    "# Add Title\n",
    "c.setFont(\"Helvetica-Bold\", 16)\n",
    "c.drawString(50, height - 50, \"Lookalike Model Report\")\n",
    "\n",
    "# Introduction Section\n",
    "c.setFont(\"Helvetica\", 12)\n",
    "c.drawString(50, height - 100, \"Introduction:\")\n",
    "c.drawString(50, height - 120, \"This report presents the results of the Lookalike Model built on the eCommerce dataset. The model identifies similar customers based on their transactional and profile data.\")\n",
    "\n",
    "# Methodology Section\n",
    "c.drawString(50, height - 160, \"Methodology:\")\n",
    "c.drawString(50, height - 180, \"1. Data Merging: Merged customer and transaction data to create a unified dataset.\")\n",
    "c.drawString(50, height - 200, \"2. Feature Extraction: Generated features including total spending, quantity, average product price, and most purchased category.\")\n",
    "c.drawString(50, height - 220, \"3. Cosine Similarity: Calculated cosine similarity between customers based on extracted features.\")\n",
    "c.drawString(50, height - 240, \"4. Top N Recommendations: For each customer, the model recommends the top 3 most similar customers.\")\n",
    "\n",
    "# Results Section\n",
    "c.drawString(50, height - 280, \"Results:\")\n",
    "c.drawString(50, height - 300, \"Below are the top 3 similar customers for the first 5 customers in the dataset:\")\n",
    "\n",
    "# Table of Recommendations (showing first 5 rows)\n",
    "y_position = height - 340\n",
    "c.setFont(\"Helvetica\", 10)\n",
    "for i, row in lookalike_df.head(5).iterrows():\n",
    "    c.drawString(50, y_position, f\"Customer: {row['CustomerID']} -> Lookalike: {row['LookalikeID']} -> Similarity Score: {row['SimilarityScore']}\")\n",
    "    y_position -= 20\n",
    "\n",
    "# Conclusion Section\n",
    "c.drawString(50, y_position - 40, \"Conclusion:\")\n",
    "c.drawString(50, y_position - 60, \"The Lookalike Model can be used to identify similar customers for targeted marketing strategies.\")\n",
    "c.drawString(50, y_position - 80, \"By leveraging the model, businesses can increase customer engagement and optimize marketing campaigns.\")\n",
    "\n",
    "# Save the PDF\n",
    "c.save()\n",
    "\n",
    "# Notify the user\n",
    "print(f\"PDF report generated: {pdf_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7342eec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6ad840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
